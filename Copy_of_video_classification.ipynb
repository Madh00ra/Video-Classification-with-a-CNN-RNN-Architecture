{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madh00ra/Video-Classification-with-a-CNN-RNN-Architecture/blob/main/Copy_of_video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAQsqcnpocx7"
      },
      "source": [
        "# Video Classification with a CNN-RNN Architecture\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/05/28<br>\n",
        "**Last modified:** 2023/12/08<br>\n",
        "**Description:** Training a video classifier with transfer learning and a recurrent model on the UCF101 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39-SaPnocx-"
      },
      "source": [
        "This example demonstrates video classification, an important use-case with\n",
        "applications in recommendations, security, and so on.\n",
        "We will be using the [UCF101 dataset](https://www.crcv.ucf.edu/data/UCF101.php)\n",
        "to build our video classifier. The dataset consists of videos categorized into different\n",
        "actions, like cricket shot, punching, biking, etc. This dataset is commonly used to\n",
        "build action recognizers, which are an application of video classification.\n",
        "\n",
        "A video consists of an ordered sequence of frames. Each frame contains *spatial*\n",
        "information, and the sequence of those frames contains *temporal* information. To model\n",
        "both of these aspects, we use a hybrid architecture that consists of convolutions\n",
        "(for spatial processing) as well as recurrent layers (for temporal processing).\n",
        "Specifically, we'll use a Convolutional Neural Network (CNN) and a Recurrent Neural\n",
        "Network (RNN) consisting of [GRU layers](https://keras.io/api/layers/recurrent_layers/gru/).\n",
        "This kind of hybrid architecture is popularly known as a **CNN-RNN**.\n",
        "\n",
        "This example requires TensorFlow 2.5 or higher, as well as TensorFlow Docs, which can be\n",
        "installed using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gSw0w_IocyB",
        "outputId": "e1d34668-44e3-4658-d070-35972799b6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow5sqS2UocyD"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "In order to keep the runtime of this example relatively short, we will be using a\n",
        "subsampled version of the original UCF101 dataset. You can refer to\n",
        "[this notebook](https://colab.research.google.com/github/sayakpaul/Action-Recognition-in-TensorFlow/blob/main/Data_Preparation_UCF101.ipynb)\n",
        "to know how the subsampling was done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbFxApSMocyE"
      },
      "outputs": [],
      "source": [
        "!!wget -q https://github.com/sayakpaul/Action-Recognition-in-TensorFlow/releases/download/v1.0.0/ucf101_top5.tar.gz\n",
        "!tar xf ucf101_top5.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHOrbRt3ocyF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ7ZhxjuocyG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSTReoJHocyH"
      },
      "source": [
        "## Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6ncmKgwocyI"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDQUMp3ZocyJ"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ejXvl0yOocyJ",
        "outputId": "80da532c-e255-4c4e-e88d-aea567e3fb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 594\n",
            "Total videos for testing: 224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     video_name           tag\n",
              "274         v_Punch_g13_c03.avi         Punch\n",
              "383  v_ShavingBeard_g11_c04.avi  ShavingBeard\n",
              "546   v_TennisSwing_g18_c01.avi   TennisSwing\n",
              "277         v_Punch_g13_c06.avi         Punch\n",
              "106   v_CricketShot_g24_c03.avi   CricketShot\n",
              "290         v_Punch_g15_c05.avi         Punch\n",
              "122  v_PlayingCello_g08_c05.avi  PlayingCello\n",
              "447  v_ShavingBeard_g21_c05.avi  ShavingBeard\n",
              "295         v_Punch_g16_c04.avi         Punch\n",
              "462  v_ShavingBeard_g23_c06.avi  ShavingBeard"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fb6ee22-87e4-46d5-8ef7-e560f63f840c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>v_Punch_g13_c03.avi</td>\n",
              "      <td>Punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>v_ShavingBeard_g11_c04.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>v_TennisSwing_g18_c01.avi</td>\n",
              "      <td>TennisSwing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>v_Punch_g13_c06.avi</td>\n",
              "      <td>Punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>v_CricketShot_g24_c03.avi</td>\n",
              "      <td>CricketShot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>v_Punch_g15_c05.avi</td>\n",
              "      <td>Punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>v_PlayingCello_g08_c05.avi</td>\n",
              "      <td>PlayingCello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>v_ShavingBeard_g21_c05.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>v_Punch_g16_c04.avi</td>\n",
              "      <td>Punch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>v_ShavingBeard_g23_c06.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fb6ee22-87e4-46d5-8ef7-e560f63f840c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fb6ee22-87e4-46d5-8ef7-e560f63f840c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fb6ee22-87e4-46d5-8ef7-e560f63f840c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d89da8e-307b-454d-aff0-34ac6ead4142\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d89da8e-307b-454d-aff0-34ac6ead4142')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d89da8e-307b-454d-aff0-34ac6ead4142 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"v_Punch_g16_c04.avi\",\n          \"v_ShavingBeard_g11_c04.avi\",\n          \"v_Punch_g15_c05.avi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ShavingBeard\",\n          \"PlayingCello\",\n          \"TennisSwing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "train_df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X50b2fYgocyK"
      },
      "source": [
        "One of the many challenges of training video classifiers is figuring out a way to feed\n",
        "the videos to a network. [This blog post](https://blog.coast.ai/five-video-classification-methods-implemented-in-keras-and-tensorflow-99cad29cc0b5)\n",
        "discusses five such methods. Since a video is an ordered sequence of frames, we could\n",
        "just extract the frames and put them in a 3D tensor. But the number of frames may differ\n",
        "from video to video which would prevent us from stacking them into batches\n",
        "(unless we use padding). As an alternative, we can **save video frames at a fixed\n",
        "interval until a maximum frame count is reached**. In this example we will do\n",
        "the following:\n",
        "\n",
        "1. Capture the frames of a video.\n",
        "2. Extract frames from the videos until a maximum frame count is reached.\n",
        "3. In the case, where a video's frame count is lesser than the maximum frame count we\n",
        "will pad the video with zeros.\n",
        "\n",
        "Note that this workflow is identical to [problems involving texts sequences](https://developers.google.com/machine-learning/guides/text-classification/). Videos of the UCF101 dataset is [known](https://www.crcv.ucf.edu/papers/UCF101_CRCV-TR-12-01.pdf)\n",
        "to not contain extreme variations in objects and actions across frames. Because of this,\n",
        "it may be okay to only consider a few frames for the learning task. But this approach may\n",
        "not generalize well to other video classification problems. We will be using\n",
        "[OpenCV's `VideoCapture()` method](https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html)\n",
        "to read frames from videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZE4MuP2ocyL"
      },
      "outputs": [],
      "source": [
        "# The following two methods are taken from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjoh3YC5ocyM"
      },
      "source": [
        "We can use a pre-trained network to extract meaningful features from the extracted\n",
        "frames. The [`Keras Applications`](https://keras.io/api/applications/) module provides\n",
        "a number of state-of-the-art models pre-trained on the [ImageNet-1k dataset](http://image-net.org/).\n",
        "We will be using the [InceptionV3 model](https://arxiv.org/abs/1512.00567) for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gngHBBpocyN",
        "outputId": "ec0f1655-6dd3-449c-dfc4-ed9436e1d7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se40MtuLocyN"
      },
      "source": [
        "The labels of the videos are strings. Neural networks do not understand string values,\n",
        "so they must be converted to some numerical form before they are fed to the model. Here\n",
        "we will use the [`StringLookup`](https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup)\n",
        "layer encode the class labels as integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3XnU8PVocyO",
        "outputId": "e1df7dcb-d7cf-4ca4-b233-f6dc661977a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing']\n"
          ]
        }
      ],
      "source": [
        "label_processor = keras.layers.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ks_pYpgocyP"
      },
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc1nzccOocyP",
        "outputId": "e83c2bd5-33da-46cc-f0de-d1c76cee7672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (594, 100, 2048)\n",
            "Frame masks in train set: (594, 100)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define constants used in the script\n",
        "MAX_SEQ_LENGTH = 100  # Example value, adjust according to your needs\n",
        "NUM_FEATURES = 2048  # Example value, adjust according to your needs\n",
        "\n",
        "# Define the feature extractor function (replace this with your actual function)\n",
        "def feature_extractor(batch):\n",
        "    # This is a placeholder. Replace with your actual feature extraction logic.\n",
        "    return np.random.rand(1, NUM_FEATURES)\n",
        "\n",
        "# Define the load_video function (replace this with your actual function)\n",
        "def load_video(path):\n",
        "    # This is a placeholder. Replace with your actual video loading logic.\n",
        "    return np.random.rand(10, 224, 224, 3)  # Example video frames\n",
        "\n",
        "# Placeholder for label_processor function (replace this with your actual function)\n",
        "def label_processor(labels):\n",
        "    # This is a placeholder. Replace with your actual label processing logic.\n",
        "    return np.random.rand(len(labels), 1)\n",
        "\n",
        "# Load data into DataFrames\n",
        "train_df = pd.read_csv(r'train.csv')\n",
        "test_df = pd.read_csv(r'test.csv')\n",
        "\n",
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    labels = df[\"tag\"].values\n",
        "    labels = tf.convert_to_tensor(label_processor(labels[..., None]))\n",
        "\n",
        "    # frame_masks and frame_features are what we will feed to our sequence model.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=bool)\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=np.float32)\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH), dtype=bool)\n",
        "        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=np.float32)\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor(batch[None, j, :])\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "# Prepare training and testing data\n",
        "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTRqgYWJocyQ"
      },
      "source": [
        "The above code block will take ~20 minutes to execute depending on the machine it's being\n",
        "executed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yff5KgRoocyQ"
      },
      "source": [
        "## The sequence model\n",
        "\n",
        "Now, we can feed this data to a sequence model consisting of recurrent layers like `GRU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o4THHfcyocyR",
        "outputId": "bd98909b-0769-4bc5-d796-d386b67ab109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/2 [==============>...............] - ETA: 8s - loss: 1.0592 - accuracy: 0.4375\n",
            "Epoch 1: val_loss improved from inf to 1.12965, saving model to ckpt.weights.h5\n",
            "2/2 [==============================] - 10s 2s/step - loss: 1.1891 - accuracy: 0.3750 - val_loss: 1.1297 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1993 - accuracy: 0.2500\n",
            "Epoch 2: val_loss improved from 1.12965 to 1.09415, saving model to ckpt.weights.h5\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.1630 - accuracy: 0.2857 - val_loss: 1.0941 - val_accuracy: 0.3750\n",
            "Epoch 3/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1841 - accuracy: 0.3125\n",
            "Epoch 3: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.1683 - accuracy: 0.3214 - val_loss: 1.0959 - val_accuracy: 0.3750\n",
            "Epoch 4/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1406 - accuracy: 0.3750\n",
            "Epoch 4: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.0977 - accuracy: 0.4286 - val_loss: 1.0955 - val_accuracy: 0.3750\n",
            "Epoch 5/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0767 - accuracy: 0.4062\n",
            "Epoch 5: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.1018 - accuracy: 0.3750 - val_loss: 1.0968 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1000 - accuracy: 0.4375\n",
            "Epoch 6: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.1294 - accuracy: 0.3750 - val_loss: 1.1014 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.2079 - accuracy: 0.2188\n",
            "Epoch 7: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.1664 - accuracy: 0.2679 - val_loss: 1.1032 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0689 - accuracy: 0.4062\n",
            "Epoch 8: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.0747 - accuracy: 0.3929 - val_loss: 1.1049 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0868 - accuracy: 0.3750\n",
            "Epoch 9: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0967 - accuracy: 0.3929 - val_loss: 1.1086 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.1165 - accuracy: 0.4375\n",
            "Epoch 10: val_loss did not improve from 1.09415\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.1060 - accuracy: 0.3929 - val_loss: 1.1117 - val_accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0783 - accuracy: 0.5000\n",
            "Test accuracy: 50.0%\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Raw predictions: [[0.3039422  0.35668644 0.3393714 ]\n",
            " [0.29938516 0.3467652  0.35384968]\n",
            " [0.30038077 0.34004608 0.3595732 ]\n",
            " [0.30090466 0.3481493  0.350946  ]\n",
            " [0.30369264 0.35737154 0.33893582]\n",
            " [0.3018651  0.35449484 0.3436401 ]\n",
            " [0.2982937  0.3548231  0.3468832 ]\n",
            " [0.3093504  0.3580992  0.3325504 ]\n",
            " [0.3028705  0.345754   0.35137552]\n",
            " [0.2990945  0.3472824  0.3536231 ]\n",
            " [0.30226734 0.34606218 0.35167047]\n",
            " [0.301236   0.34537986 0.35338417]\n",
            " [0.30146575 0.34914014 0.34939414]\n",
            " [0.30230087 0.34949565 0.34820345]\n",
            " [0.30096397 0.34174103 0.35729498]\n",
            " [0.30055422 0.34878907 0.35065666]\n",
            " [0.30239367 0.34821966 0.34938663]\n",
            " [0.29911664 0.34724802 0.35363534]\n",
            " [0.3033189  0.3521167  0.3445644 ]\n",
            " [0.30024752 0.34407526 0.3556772 ]]\n",
            "Predicted classes: ['class2' 'class3' 'class3' 'class3' 'class2' 'class2' 'class2' 'class2'\n",
            " 'class3' 'class3' 'class3' 'class3' 'class3' 'class2' 'class3' 'class3'\n",
            " 'class3' 'class3' 'class2' 'class3']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import GRU, Dropout, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your labels are defined\n",
        "labels = np.random.choice(['class1', 'class2', 'class3'], 100)  # Example labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Generate some random data to mimic frame features\n",
        "data = np.random.rand(100, 20, 2048)\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048\n",
        "EPOCHS = 10  # Reduced epochs for demonstration\n",
        "\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_encoder.classes_\n",
        "\n",
        "    frame_features_input = Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    x = GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
        "    x = GRU(8)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(8, activation=\"relu\")(x)\n",
        "    output = Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Generate mask input (not actually used in this example, but required by model)\n",
        "train_mask = np.ones((train_data.shape[0], MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "test_mask = np.ones((test_data.shape[0], MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "\n",
        "train_inputs = [train_data, train_mask]\n",
        "test_inputs = [test_data, test_mask]\n",
        "\n",
        "def run_experiment():\n",
        "    filepath = \"ckpt.weights.h5\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        train_inputs,\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate(test_inputs, test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "# Run the experiment\n",
        "_, sequence_model = run_experiment()\n",
        "\n",
        "# Make predictions\n",
        "predictions = sequence_model.predict(test_inputs)\n",
        "\n",
        "# Decode predictions\n",
        "predicted_classes = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
        "\n",
        "# Print raw predictions\n",
        "print(\"Raw predictions:\", predictions)\n",
        "\n",
        "# Print predicted classes\n",
        "print(\"Predicted classes:\", predicted_classes)\n",
        "\n",
        "# Visualize a prediction example\n",
        "plt.bar(label_encoder.classes_, predictions[0])\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"Prediction probabilities for first test example\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmLn1eKqpquL",
        "outputId": "8df5644b-5f8d-435d-9892-a87915ee8d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8mQq4z8qRTu",
        "outputId": "da654584-df08-454f-bdc5-69c0fa8ddd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSqebSAwocyS"
      },
      "source": [
        "**Note**: To keep the runtime of this example relatively short, we just used a few\n",
        "training examples. This number of training examples is low with respect to the sequence\n",
        "model being used that has 99,909 trainable parameters. You are encouraged to sample more\n",
        "data from the UCF101 dataset using [the notebook](https://colab.research.google.com/github/sayakpaul/Action-Recognition-in-TensorFlow/blob/main/Data_Preparation_UCF101.ipynb) mentioned above and train the same model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpV6AjJ5ocyT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "hgvJj3VcocyU",
        "outputId": "ae257223-220c-4de6-fe41-57584cc5f940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: video1.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ab278df9870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 1s 632ms/step\n",
            "  Class 2: 38.66%\n",
            "  Class 0: 36.53%\n",
            "  Class 1: 24.81%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.GifImagePlugin.GifImageFile image mode=P size=224x224>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input  # Example import for preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "# Define MAX_SEQ_LENGTH\n",
        "MAX_SEQ_LENGTH = 20  # Example value, adjust according to your needs\n",
        "NUM_FEATURES = 2048  # Example value, adjust according to your needs\n",
        "\n",
        "# Assuming test_df is defined or imported correctly\n",
        "test_df = pd.DataFrame({\"video_name\": [\"video1.mp4\", \"video2.mp4\", \"video3.mp4\"], \"label\": [0, 1, 2]})\n",
        "\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "sequence_model = Sequential([\n",
        "    Input(shape=(MAX_SEQ_LENGTH, NUM_FEATURES)),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(3, activation='softmax')  # Adjust the number of units and activation as per your classification task\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "sequence_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save the model for future loading (if needed)\n",
        "sequence_model.save('models/your_model.h5')\n",
        "\n",
        "\n",
        "def prepare_single_video(frames, max_seq_length, num_features, feature_extractor):\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, num_features), dtype=\"float32\")\n",
        "\n",
        "    # Process each frame\n",
        "    for i, frame in enumerate(frames):\n",
        "        if i >= max_seq_length:\n",
        "            break\n",
        "        # Preprocess frame (resize, normalize, etc.) as needed for ResNet50\n",
        "        processed_frame = preprocess_input(frame)\n",
        "        features = feature_extractor.predict(processed_frame[None, ...])\n",
        "        frame_features[0, i, :] = features\n",
        "\n",
        "    return frame_features\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    frames = np.random.rand(10, 224, 224, 3)  # Example frames\n",
        "    frame_features = prepare_single_video(frames, MAX_SEQ_LENGTH, NUM_FEATURES, feature_extractor)\n",
        "    probabilities = sequence_model.predict(frame_features)\n",
        "\n",
        "    sorted_indices = np.argsort(probabilities[0])[::-1]\n",
        "    for i in sorted_indices:\n",
        "        print(f\"  Class {i}: {probabilities[0][i] * 100:5.2f}%\")\n",
        "\n",
        "    return frames\n",
        "\n",
        "# This utility is for visualization.\n",
        "# Referenced from:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def to_gif(images):\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, duration=100)\n",
        "    return Image.open(\"animation.gif\")\n",
        "\n",
        "\n",
        "# Rest of your code\n",
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "#test_video = \"video1.mp4\"  # Example video path\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = sequence_prediction(test_video)\n",
        "to_gif(test_frames[:MAX_SEQ_LENGTH])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9SUvmrBocyU"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "* In this example, we made use of transfer learning for extracting meaningful features\n",
        "from video frames. You could also fine-tune the pre-trained network to notice how that\n",
        "affects the end results.\n",
        "* For speed-accuracy trade-offs, you can try out other models present inside\n",
        "`keras.applications`.\n",
        "* Try different combinations of `MAX_SEQ_LENGTH` to observe how that affects the\n",
        "performance.\n",
        "* Train on a higher number of classes and see if you are able to get good performance.\n",
        "* Following [this tutorial](https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub), try a\n",
        "[pre-trained action recognition model](https://arxiv.org/abs/1705.07750) from DeepMind.\n",
        "* Rolling-averaging can be useful technique for video classification and it can be\n",
        "combined with a standard image classification model to infer on videos.\n",
        "[This tutorial](https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/)\n",
        "will help understand how to use rolling-averaging with an image classifier.\n",
        "* When there are variations in between the frames of a video not all the frames might be\n",
        "equally important to decide its category. In those situations, putting a\n",
        "[self-attention layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention) in the\n",
        "sequence model will likely yield better results.\n",
        "* Following [this book chapter](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11),\n",
        "you can implement Transformers-based models for processing videos."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}